╔══════════════════════════════════════════════════════════════════════════════╗
║                   INSTA_RAG DOCUMENT UPLOAD PIPELINE                         ║
╚══════════════════════════════════════════════════════════════════════════════╝

                                 USER INPUT
                                     │
                                     ▼
        ┌────────────────────────────────────────────────────┐
        │  PHASE 1: DOCUMENT LOADING                         │
        │  ─────────────────────────                         │
        │  • Read file path or text input                    │
        │  • Generate unique document_id (UUID)              │
        │  • Merge metadata                                  │
        └───────────────────┬────────────────────────────────┘
                            │
                            ▼
        ┌────────────────────────────────────────────────────┐
        │  PHASE 2: TEXT EXTRACTION                          │
        │  ───────────────────────                           │
        │  • Detect file type (.pdf, .txt, .md)              │
        │  • Extract with pdfplumber (primary)               │
        │  • Fallback to PyPDF2 if needed                    │
        │  • Join pages with double newlines                 │
        │                                                     │
        │  Input:  document.pdf (50 pages)                   │
        │  Output: "This is page 1...\n\nThis is page 2..." │
        └───────────────────┬────────────────────────────────┘
                            │
                            ▼
        ┌────────────────────────────────────────────────────┐
        │  PHASE 3: SEMANTIC CHUNKING                        │
        │  ─────────────────────────                         │
        │  Step 1: Split into sentences                      │
        │          ["Sent 1.", "Sent 2.", ...]               │
        │                                                     │
        │  Step 2: Embed sentences                           │
        │          [[0.1, 0.2, ...], [0.15, 0.19, ...]]     │
        │                                                     │
        │  Step 3: Calculate similarities                    │
        │          [0.95, 0.92, 0.45 ← low!, 0.88, ...]     │
        │                                                     │
        │  Step 4: Find breakpoints (topic changes)          │
        │          Break at indices: [3, 7, 12]              │
        │                                                     │
        │  Step 5: Create chunks + add 20% overlap           │
        │                                                     │
        │  Input:  25,000 words                              │
        │  Output: 18 semantic chunks (avg 1,389 words)      │
        └───────────────────┬────────────────────────────────┘
                            │
                            ▼
        ┌────────────────────────────────────────────────────┐
        │  PHASE 4: CHUNK VALIDATION                         │
        │  ────────────────────────                          │
        │  • Validate minimum length (>= 10 chars)           │
        │  • Count tokens per chunk                          │
        │  • Create ChunkMetadata objects                    │
        │                                                     │
        │  Each chunk has:                                   │
        │  - chunk_id: "uuid_chunk_0"                        │
        │  - content: "Chunk text..."                        │
        │  - metadata: {document_id, source, tokens, ...}    │
        └───────────────────┬────────────────────────────────┘
                            │
                            ▼
        ┌────────────────────────────────────────────────────┐
        │  PHASE 5: BATCH EMBEDDING GENERATION               │
        │  ──────────────────────────────────                │
        │  • Extract content from all chunks                 │
        │  • Batch into groups of 100                        │
        │  • Call Azure OpenAI API:                          │
        │    - Model: text-embedding-3-large                 │
        │    - Output: 3072-dimensional vectors              │
        │  • Attach embeddings to chunk objects              │
        │                                                     │
        │  Input:  18 chunks                                 │
        │  Output: 18 × [3072 floats]                        │
        │          Example: [0.023, -0.012, 0.045, ...]      │
        └───────────────────┬────────────────────────────────┘
                            │
                            ▼
        ┌────────────────────────────────────────────────────┐
        │  PHASE 6: VECTOR & CONTENT STORAGE                 │
        │  ────────────────────────────────                  │
        │                                                     │
        │  ┌─────────────────────────────────────────┐       │
        │  │ 6A: Create/Verify Qdrant Collection     │       │
        │  │     - Name: "my_documents"              │       │
        │  │     - Vector size: 3072                 │       │
        │  │     - Distance: COSINE                  │       │
        │  └─────────────────────────────────────────┘       │
        │                                                     │
        │  ┌─────────────────────┬───────────────────────┐   │
        │  │  MongoDB Enabled?   │                       │   │
        │  └──────────┬──────────┴───────────────────────┘   │
        │             │                                       │
        │      YES ───┴─── NO                                │
        │       │            │                                │
        │       ▼            ▼                                │
        │  ┌─────────┐  ┌──────────────┐                     │
        │  │ HYBRID  │  │ QDRANT-ONLY  │                     │
        │  │  MODE   │  │     MODE     │                     │
        │  └─────────┘  └──────────────┘                     │
        └───────┬────────────┬───────────────────────────────┘
                │            │
                ▼            ▼

    ┌───────────────────┐         ┌──────────────────────┐
    │   HYBRID MODE     │         │   QDRANT-ONLY MODE   │
    │   ───────────     │         │   ──────────────     │
    │                   │         │                      │
    │   MongoDB:        │         │   Qdrant:            │
    │   ─────────       │         │   ───────            │
    │   {               │         │   {                  │
    │     chunk_id,     │         │     id: uuid,        │
    │     content: "...",│        │     vector: [...],   │
    │     metadata      │         │     payload: {       │
    │   }               │         │       content: "...", │
    │                   │         │       chunk_id,      │
    │   Qdrant:         │         │       metadata       │
    │   ───────         │         │     }                │
    │   {               │         │   }                  │
    │     id: uuid,     │         │                      │
    │     vector: [...],│         │   All data in        │
    │     payload: {    │         │   single store       │
    │       mongodb_id, │         │                      │
    │       metadata    │         │                      │
    │     }             │         │                      │
    │   }               │         │                      │
    │                   │         │                      │
    │   Content in      │         │                      │
    │   MongoDB,        │         │                      │
    │   Vectors in      │         │                      │
    │   Qdrant          │         │                      │
    └───────────────────┘         └──────────────────────┘

╔══════════════════════════════════════════════════════════════════════════════╗
║                              FINAL RESULT                                    ║
╚══════════════════════════════════════════════════════════════════════════════╝

Qdrant Collection: "my_documents"
├── Point 0: id="uuid-0", vector=[3072 dims], payload={chunk_id, metadata...}
├── Point 1: id="uuid-1", vector=[3072 dims], payload={chunk_id, metadata...}
├── Point 2: id="uuid-2", vector=[3072 dims], payload={chunk_id, metadata...}
...
└── Point 17: id="uuid-17", vector=[3072 dims], payload={chunk_id, metadata...}

Status: ✅ Ready for semantic search
Vector Similarity: COSINE distance
Searchable Fields: All metadata fields + content (if not in MongoDB)

╔══════════════════════════════════════════════════════════════════════════════╗
║                           PERFORMANCE STATS                                  ║
╚══════════════════════════════════════════════════════════════════════════════╝

Example for 1 PDF (50 pages):
  • Chunking:   1,250 ms  (Phase 3)
  • Embedding:  3,421 ms  (Phase 5)
  • Upload:       890 ms  (Phase 6)
  • ─────────────────────
  • TOTAL:      5,561 ms  (~5.6 seconds)

  Documents:   1
  Chunks:      18
  Tokens:      12,500
  Vectors:     18 × 3072 dimensions
  Storage:     Qdrant + MongoDB (hybrid)

╔══════════════════════════════════════════════════════════════════════════════╗
║                      KEY TECHNICAL DECISIONS                                 ║
╚══════════════════════════════════════════════════════════════════════════════╝

1. Semantic Chunking
   └─ Analyzes sentence similarity to find natural topic boundaries
   └─ Better than fixed-size chunks for preserving context

2. Deterministic UUIDs
   └─ uuid.uuid5(NAMESPACE_DNS, chunk_id)
   └─ Same chunk always gets same ID → idempotent uploads

3. Hybrid Storage
   └─ Qdrant: Fast vector search (optimized for embeddings)
   └─ MongoDB: Cheaper text storage
   └─ Best of both worlds

4. Batch Processing
   └─ 100 chunks per API call
   └─ Reduces latency and costs

5. 20% Overlap
   └─ Prevents information loss at chunk boundaries
   └─ Improves retrieval quality
